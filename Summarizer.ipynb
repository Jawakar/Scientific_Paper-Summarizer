{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summarizer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b770e6fc8fd14aeaaa41fccbbac6c45b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81037b94f1c3460e9160026731a6b3d5",
              "IPY_MODEL_ca52308efdd24fbdb8bb6b067094d3f6",
              "IPY_MODEL_25fe49ce10184ed0a1b1c97c6cfd3797"
            ],
            "layout": "IPY_MODEL_d94ee401aef54542bd17b5fb74be3c51"
          }
        },
        "81037b94f1c3460e9160026731a6b3d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b448e38a30bf492281ccbf0e42e98e09",
            "placeholder": "​",
            "style": "IPY_MODEL_0fe3b767c3514767a0dd4cf15fdd4f52",
            "value": "100%"
          }
        },
        "ca52308efdd24fbdb8bb6b067094d3f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c937a2795d5c49f5a35726faa3a44877",
            "max": 1009,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ce10b5b2e65431c919a3c2f6e3d0191",
            "value": 1009
          }
        },
        "25fe49ce10184ed0a1b1c97c6cfd3797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7585524517424596b07f0c99c0f0b8bb",
            "placeholder": "​",
            "style": "IPY_MODEL_57843b2cba44448faf49cffba349ab6a",
            "value": " 1009/1009 [20:08&lt;00:00,  1.13s/it]"
          }
        },
        "d94ee401aef54542bd17b5fb74be3c51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b448e38a30bf492281ccbf0e42e98e09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fe3b767c3514767a0dd4cf15fdd4f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c937a2795d5c49f5a35726faa3a44877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ce10b5b2e65431c919a3c2f6e3d0191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7585524517424596b07f0c99c0f0b8bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57843b2cba44448faf49cffba349ab6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c402b78302e64d3b890ea26766b748a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_acc1df52ad614a36861e37c8e56a3ba5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1fce8d38a8bb4eaa9e56fb1dd10f6416",
              "IPY_MODEL_3d8c6d784f5f42bfa056a5f7cf193a43",
              "IPY_MODEL_2714ef02e0254d3ab9c90c7bb4408c8a"
            ]
          }
        },
        "acc1df52ad614a36861e37c8e56a3ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fce8d38a8bb4eaa9e56fb1dd10f6416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4a911129ca39438cbf3fbffa8123cf80",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd4e67b9087c45cd94e13cf1846c9157"
          }
        },
        "3d8c6d784f5f42bfa056a5f7cf193a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_57a674f194da42d28ada5d133792a981",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 203,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 203,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_078e84617e604fe0926fe5b52e590d41"
          }
        },
        "2714ef02e0254d3ab9c90c7bb4408c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ec205eba934c47a696cc9062158d6784",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 203/203 [2:19:00&lt;00:00, 41.06s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9067b241fb146269d82c0b1ce8a8a33"
          }
        },
        "4a911129ca39438cbf3fbffa8123cf80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd4e67b9087c45cd94e13cf1846c9157": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "57a674f194da42d28ada5d133792a981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "078e84617e604fe0926fe5b52e590d41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec205eba934c47a696cc9062158d6784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9067b241fb146269d82c0b1ce8a8a33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVLayuC8bjhE"
      },
      "source": [
        "#Buiding dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShEY-JtaBRTb",
        "outputId": "855768e5-3cd5-470e-c3df-94d047ed18f3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbhI40A6Nrlh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9355ebb-1d8b-4f0d-ce90-8850aa962a6e"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "!pip install PyPDF2\n",
        "import PyPDF2\n",
        "from lxml import etree\n",
        "from tqdm.auto import tqdm\n",
        "!pip install torch\n",
        "!pip install -Uq transformers\n",
        "!pip install -r '/content/drive/MyDrive/Datasests/Scisummnet/requirements.txt'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading PyPDF2-1.26.0.tar.gz (77 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 20.4 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 3.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyPDF2\n",
            "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-py3-none-any.whl size=61101 sha256=7fbe9cd731e0c0a7510a81a154767849e8b516e4773abf87e4b214860e4c3231\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1a/24/648467ade3a77ed20f35cfd2badd32134e96dd25ca811e64b3\n",
            "Successfully built PyPDF2\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-1.26.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 37.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 38.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 35.4 MB/s \n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.4.0-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting datasets>=1.8.0\n",
            "  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n",
            "\u001b[K     |████████████████████████████████| 264 kB 11.1 MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 39.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 4)) (3.17.3)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 6)) (3.2.5)\n",
            "Collecting py7zr\n",
            "  Downloading py7zr-0.16.1-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 8)) (1.9.0+cu102)\n",
            "Collecting fsspec>=2021.05.0\n",
            "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 45.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (21.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (4.62.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 45.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (0.70.12.2)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (0.0.12)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (1.1.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (4.6.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (0.3.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 8)) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (2021.5.30)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from accelerate->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 1)) (5.4.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 5)) (0.12.0)\n",
            "Collecting bcj-cffi<0.6.0,>=0.5.1\n",
            "  Downloading bcj_cffi-0.5.1-cp37-cp37m-manylinux2014_x86_64.whl (36 kB)\n",
            "Collecting pyzstd<0.15.0,>=0.14.4\n",
            "  Downloading pyzstd-0.14.4-cp37-cp37m-manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 32.9 MB/s \n",
            "\u001b[?25hCollecting pyppmd>=0.14.0\n",
            "  Downloading pyppmd-0.16.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 44.3 MB/s \n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting brotli>=1.0.9\n",
            "  Downloading Brotli-1.0.9-cp37-cp37m-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[K     |████████████████████████████████| 357 kB 44.3 MB/s \n",
            "\u001b[?25hCollecting texttable\n",
            "  Downloading texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pycryptodomex>=3.6.6\n",
            "  Downloading pycryptodomex-3.10.1-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 35.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from bcj-cffi<0.6.0,>=0.5.1->py7zr->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 7)) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.14.0->bcj-cffi<0.6.0,>=0.5.1->py7zr->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 7)) (2.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.8.0->-r /content/drive/MyDrive/Datasests/Scisummnet/requirements.txt (line 2)) (2.8.2)\n",
            "Installing collected packages: xxhash, texttable, pyzstd, pyppmd, pycryptodomex, multivolumefile, fsspec, brotli, bcj-cffi, sentencepiece, rouge-score, py7zr, datasets, accelerate\n",
            "Successfully installed accelerate-0.4.0 bcj-cffi-0.5.1 brotli-1.0.9 datasets-1.11.0 fsspec-2021.7.0 multivolumefile-0.2.3 py7zr-0.16.1 pycryptodomex-3.10.1 pyppmd-0.16.1 pyzstd-0.14.4 rouge-score-0.0.4 sentencepiece-0.1.96 texttable-1.6.4 xxhash-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AUqWKv6PQmo"
      },
      "source": [
        "root_path = '/content/drive/MyDrive/Datasests/Scisummnet/scisummnet_release1.1__20190413 (3).zip (Unzipped Files)/scisummnet_release1.1__20190413/top1000_complete'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlE1IGsSP89G"
      },
      "source": [
        "# getting list of all files and directories in the specified directory\n",
        "pathlist = os.listdir(root_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b770e6fc8fd14aeaaa41fccbbac6c45b",
            "81037b94f1c3460e9160026731a6b3d5",
            "ca52308efdd24fbdb8bb6b067094d3f6",
            "25fe49ce10184ed0a1b1c97c6cfd3797",
            "d94ee401aef54542bd17b5fb74be3c51",
            "b448e38a30bf492281ccbf0e42e98e09",
            "0fe3b767c3514767a0dd4cf15fdd4f52",
            "c937a2795d5c49f5a35726faa3a44877",
            "6ce10b5b2e65431c919a3c2f6e3d0191",
            "7585524517424596b07f0c99c0f0b8bb",
            "57843b2cba44448faf49cffba349ab6a"
          ]
        },
        "id": "qtgUR1U7Qdtn",
        "outputId": "cb175f66-5d6b-4629-8415-cf51f0d9b9a6"
      },
      "source": [
        "parser = etree.XMLParser(remove_blank_text=True)\n",
        "pap_text = []\n",
        "summaries = []\n",
        "for folder in tqdm(pathlist):\n",
        "    tree = etree.parse(root_path+'/'+folder+'/Documents_xml/'+folder+'.xml', parser)\n",
        "    paper = []\n",
        "    for s in tree.iter():\n",
        "        if s.text is not None: paper.append(s.text)\n",
        "\n",
        "    with open(root_path+'/'+folder+'/summary/'+folder+'.gold.txt') as f:\n",
        "        lines = f.read()\n",
        "\n",
        "    pap_text.append(' '.join(paper))\n",
        "    summaries.append(lines)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b770e6fc8fd14aeaaa41fccbbac6c45b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1009 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCy0j-weQ2Jn"
      },
      "source": [
        "scisum_df = pd.DataFrame({'text': pap_text, 'summary': summaries})\n",
        "scisum_df.to_csv('./scisumm.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLU3gbsUb6ur"
      },
      "source": [
        "#Splitting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2u3NWnNZSvS"
      },
      "source": [
        "scisum_df = pd.read_csv('/content/drive/MyDrive/Datasests/Scisummnet/scisumm.csv')\n",
        "\n",
        "# Manual train-test split\n",
        "np.random.seed(10)\n",
        "msk = np.random.rand(len(scisum_df)) < 0.8\n",
        "scisum_train_df = scisum_df[msk]\n",
        "scisum_test_df = scisum_df[~msk]\n",
        "scisum_train_df.to_csv('/content/drive/MyDrive/Datasests/Scisummnet/scisumm_train.csv')\n",
        "scisum_test_df.to_csv('/content/drive/MyDrive/Datasests/Scisummnet/scisumm_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYrvdonvdWlZ",
        "outputId": "0feae66b-38e8-4e9b-cec1-d4c04634d225"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git\n",
        "os.chdir(\"/content/transformers\")\n",
        "!pwd\n",
        "!pip install -e .\n",
        "\n",
        "!python '/content/drive/MyDrive/Datasests/Scisummnet/run_summarization.py' \\\n",
        "    --model_name_or_path facebook/bart-large-cnn \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --train_file '/content/drive/MyDrive/Datasests/Scisummnet/scisumm_train.csv' \\\n",
        "    --validation_file '/content/drive/MyDrive/Datasests/Scisummnet/scisumm_test.csv' \\\n",
        "    --text_column text \\\n",
        "    --summary_column summary \\\n",
        "    --source_prefix \"summarize: \" \\\n",
        "    --output_dir \"/content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/\" \\\n",
        "    --overwrite_output_dir \\\n",
        "    --per_device_train_batch_size=1 \\\n",
        "    --per_device_eval_batch_size=1 \\\n",
        "    --predict_with_generate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "fatal: could not create work tree dir 'transformers': No such file or directory\n",
            "/content/transformers\n",
            "Obtaining file:///content/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (4.6.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (4.62.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (0.10.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (0.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (3.0.12)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers==4.10.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.10.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.10.0.dev0) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0.dev0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.0.dev0) (2021.5.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.0.dev0) (7.1.2)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.9.2\n",
            "    Uninstalling transformers-4.9.2:\n",
            "      Successfully uninstalled transformers-4.9.2\n",
            "  Running setup.py develop for transformers\n",
            "Successfully installed transformers-4.10.0.dev0\n",
            "08/27/2021 12:10:40 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "08/27/2021 12:10:40 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/runs/Aug27_12-10-40_e4dc6d6d2b63,\n",
            "logging_first_step=False,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "output_dir=/content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=1,\n",
            "per_device_train_batch_size=1,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=Summarization Output,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=None,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "08/27/2021 12:10:40 - WARNING - datasets.builder - Using custom data configuration default-4512316ad4b347ae\n",
            "08/27/2021 12:10:40 - INFO - datasets.builder - Generating dataset csv (/root/.cache/huggingface/datasets/csv/default-4512316ad4b347ae/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n",
            "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-4512316ad4b347ae/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff...\n",
            "100% 2/2 [00:00<00:00, 3474.98it/s]\n",
            "08/27/2021 12:10:40 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\n",
            "08/27/2021 12:10:41 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\n",
            "100% 2/2 [00:00<00:00, 82.83it/s]\n",
            "08/27/2021 12:10:41 - INFO - datasets.utils.info_utils - Unable to verify checksums.\n",
            "08/27/2021 12:10:41 - INFO - datasets.builder - Generating split train\n",
            "08/27/2021 12:10:42 - INFO - datasets.builder - Generating split validation\n",
            "08/27/2021 12:10:42 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-4512316ad4b347ae/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff. Subsequent calls will reuse this data.\n",
            "100% 2/2 [00:00<00:00, 392.73it/s]\n",
            "[INFO|file_utils.py:1632] 2021-08-27 12:10:42,525 >> https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmprifdu40g\n",
            "Downloading: 100% 1.58k/1.58k [00:00<00:00, 1.05MB/s]\n",
            "[INFO|file_utils.py:1636] 2021-08-27 12:10:42,698 >> storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n",
            "[INFO|file_utils.py:1644] 2021-08-27 12:10:42,698 >> creating metadata file for /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n",
            "[INFO|configuration_utils.py:561] 2021-08-27 12:10:42,699 >> loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n",
            "[INFO|configuration_utils.py:598] 2021-08-27 12:10:42,701 >> Model config BartConfig {\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 12,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"force_bos_token_to_be_generated\": true,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 2.0,\n",
            "  \"max_length\": 142,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"min_length\": 56,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": \" \",\n",
            "  \"scale_embedding\": false,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.10.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:331] 2021-08-27 12:10:42,832 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:561] 2021-08-27 12:10:42,957 >> loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n",
            "[INFO|configuration_utils.py:598] 2021-08-27 12:10:42,957 >> Model config BartConfig {\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 12,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"force_bos_token_to_be_generated\": true,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 2.0,\n",
            "  \"max_length\": 142,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"min_length\": 56,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": \" \",\n",
            "  \"scale_embedding\": false,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.10.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "[INFO|file_utils.py:1632] 2021-08-27 12:10:43,220 >> https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp8w24yfme\n",
            "Downloading: 100% 899k/899k [00:00<00:00, 6.10MB/s]\n",
            "[INFO|file_utils.py:1636] 2021-08-27 12:10:43,538 >> storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/4d8eeedc3498bc73a4b72411ebb3219209b305663632d77a6f16e60790b18038.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "[INFO|file_utils.py:1644] 2021-08-27 12:10:43,538 >> creating metadata file for /root/.cache/huggingface/transformers/4d8eeedc3498bc73a4b72411ebb3219209b305663632d77a6f16e60790b18038.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "[INFO|file_utils.py:1632] 2021-08-27 12:10:43,671 >> https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp4z0ox3nn\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 4.08MB/s]\n",
            "[INFO|file_utils.py:1636] 2021-08-27 12:10:43,938 >> storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/0ddddd3ca9e107b17a6901c92543692272af1c3238a8d7549fa937ba0057bbcf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|file_utils.py:1644] 2021-08-27 12:10:43,938 >> creating metadata file for /root/.cache/huggingface/transformers/0ddddd3ca9e107b17a6901c92543692272af1c3238a8d7549fa937ba0057bbcf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|file_utils.py:1632] 2021-08-27 12:10:44,066 >> https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp17sjfm1v\n",
            "Downloading: 100% 1.36M/1.36M [00:00<00:00, 7.13MB/s]\n",
            "[INFO|file_utils.py:1636] 2021-08-27 12:10:44,403 >> storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/55c96bd962ce1d360fde4947619318f1b4eb551430de678044699cbfeb99de6a.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
            "[INFO|file_utils.py:1644] 2021-08-27 12:10:44,403 >> creating metadata file for /root/.cache/huggingface/transformers/55c96bd962ce1d360fde4947619318f1b4eb551430de678044699cbfeb99de6a.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
            "[INFO|tokenization_utils_base.py:1739] 2021-08-27 12:10:44,774 >> loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/4d8eeedc3498bc73a4b72411ebb3219209b305663632d77a6f16e60790b18038.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "[INFO|tokenization_utils_base.py:1739] 2021-08-27 12:10:44,774 >> loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/0ddddd3ca9e107b17a6901c92543692272af1c3238a8d7549fa937ba0057bbcf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|tokenization_utils_base.py:1739] 2021-08-27 12:10:44,774 >> loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/55c96bd962ce1d360fde4947619318f1b4eb551430de678044699cbfeb99de6a.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
            "[INFO|tokenization_utils_base.py:1739] 2021-08-27 12:10:44,774 >> loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1739] 2021-08-27 12:10:44,774 >> loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1739] 2021-08-27 12:10:44,775 >> loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:561] 2021-08-27 12:10:44,901 >> loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n",
            "[INFO|configuration_utils.py:598] 2021-08-27 12:10:44,902 >> Model config BartConfig {\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 12,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"force_bos_token_to_be_generated\": true,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 2.0,\n",
            "  \"max_length\": 142,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"min_length\": 56,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": \" \",\n",
            "  \"scale_embedding\": false,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.10.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "[INFO|file_utils.py:1632] 2021-08-27 12:10:45,130 >> https://huggingface.co/facebook/bart-large-cnn/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpe2149hrp\n",
            "Downloading: 100% 1.63G/1.63G [00:42<00:00, 38.3MB/s]\n",
            "[INFO|file_utils.py:1636] 2021-08-27 12:11:27,699 >> storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/4ccdf4cdc01b790f9f9c636c7695b5d443180e8dbd0cbe49e07aa918dda1cef0.fa29468c10a34ef7f6cfceba3b174d3ccc95f8d755c3ca1b829aff41cc92a300\n",
            "[INFO|file_utils.py:1644] 2021-08-27 12:11:27,700 >> creating metadata file for /root/.cache/huggingface/transformers/4ccdf4cdc01b790f9f9c636c7695b5d443180e8dbd0cbe49e07aa918dda1cef0.fa29468c10a34ef7f6cfceba3b174d3ccc95f8d755c3ca1b829aff41cc92a300\n",
            "[INFO|modeling_utils.py:1279] 2021-08-27 12:11:27,700 >> loading weights file https://huggingface.co/facebook/bart-large-cnn/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4ccdf4cdc01b790f9f9c636c7695b5d443180e8dbd0cbe49e07aa918dda1cef0.fa29468c10a34ef7f6cfceba3b174d3ccc95f8d755c3ca1b829aff41cc92a300\n",
            "[INFO|modeling_utils.py:1524] 2021-08-27 12:11:32,956 >> All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
            "\n",
            "[INFO|modeling_utils.py:1533] 2021-08-27 12:11:32,956 >> All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large-cnn.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
            "Running tokenizer on train dataset:   0% 0/1 [00:00<?, ?ba/s]08/27/2021 12:11:44 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-4512316ad4b347ae/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-7eb6b424259adf55.arrow\n",
            "Running tokenizer on train dataset: 100% 1/1 [00:11<00:00, 11.22s/ba]\n",
            "Running tokenizer on validation dataset:   0% 0/1 [00:00<?, ?ba/s]08/27/2021 12:11:48 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-4512316ad4b347ae/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-1bdbf5af6c446d97.arrow\n",
            "Running tokenizer on validation dataset: 100% 1/1 [00:02<00:00,  2.98s/ba]\n",
            "08/27/2021 12:11:48 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/rouge/rouge.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpwxwo5rkw\n",
            "Downloading: 5.61kB [00:00, 6.29MB/s]       \n",
            "08/27/2021 12:11:48 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/rouge/rouge.py in cache at /root/.cache/huggingface/datasets/downloads/0d0c87fe5ddaca946d07349c2f5fd6835bc143561fb76ba95aa3e47503295c2e.0176a9ea14f2e537f6dfc6a072a422e7075a0cf475bb3b71e493addc7d8dde62.py\n",
            "08/27/2021 12:11:48 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/0d0c87fe5ddaca946d07349c2f5fd6835bc143561fb76ba95aa3e47503295c2e.0176a9ea14f2e537f6dfc6a072a422e7075a0cf475bb3b71e493addc7d8dde62.py\n",
            "08/27/2021 12:11:48 - INFO - datasets.load - Creating main folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/rouge/rouge.py at /root/.cache/huggingface/modules/datasets_modules/metrics/rouge\n",
            "08/27/2021 12:11:48 - INFO - datasets.load - Creating specific version folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/rouge/rouge.py at /root/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e\n",
            "08/27/2021 12:11:48 - INFO - datasets.load - Copying script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/rouge/rouge.py to /root/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e/rouge.py\n",
            "08/27/2021 12:11:48 - INFO - datasets.load - Couldn't find dataset infos file at https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/rouge/dataset_infos.json\n",
            "08/27/2021 12:11:48 - INFO - datasets.load - Creating metadata file for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/rouge/rouge.py at /root/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e/rouge.json\n",
            "[INFO|trainer.py:1164] 2021-08-27 12:11:58,741 >> ***** Running training *****\n",
            "[INFO|trainer.py:1165] 2021-08-27 12:11:58,741 >>   Num examples = 805\n",
            "[INFO|trainer.py:1166] 2021-08-27 12:11:58,742 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:1167] 2021-08-27 12:11:58,742 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:1168] 2021-08-27 12:11:58,742 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "[INFO|trainer.py:1169] 2021-08-27 12:11:58,742 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1170] 2021-08-27 12:11:58,742 >>   Total optimization steps = 2415\n",
            "{'loss': 0.7452, 'learning_rate': 3.9648033126293996e-05, 'epoch': 0.62}\n",
            " 21% 500/2415 [10:29<40:04,  1.26s/it][INFO|trainer.py:1921] 2021-08-27 12:22:27,928 >> Saving model checkpoint to /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-500\n",
            "[INFO|configuration_utils.py:391] 2021-08-27 12:22:27,935 >> Configuration saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:1001] 2021-08-27 12:22:38,632 >> Model weights saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2020] 2021-08-27 12:22:38,646 >> tokenizer config file saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2026] 2021-08-27 12:22:38,655 >> Special tokens file saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-500/special_tokens_map.json\n",
            "{'loss': 0.593, 'learning_rate': 2.9296066252587996e-05, 'epoch': 1.24}\n",
            " 41% 1000/2415 [22:33<29:33,  1.25s/it][INFO|trainer.py:1921] 2021-08-27 12:34:32,707 >> Saving model checkpoint to /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-1000\n",
            "[INFO|configuration_utils.py:391] 2021-08-27 12:34:32,719 >> Configuration saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-1000/config.json\n",
            "[INFO|modeling_utils.py:1001] 2021-08-27 12:34:42,860 >> Model weights saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-1000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2020] 2021-08-27 12:34:43,130 >> tokenizer config file saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-1000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2026] 2021-08-27 12:34:43,146 >> Special tokens file saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-1000/special_tokens_map.json\n",
            "{'loss': 0.4257, 'learning_rate': 1.894409937888199e-05, 'epoch': 1.86}\n",
            " 62% 1500/2415 [34:35<19:12,  1.26s/it][INFO|trainer.py:1921] 2021-08-27 12:46:34,424 >> Saving model checkpoint to /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-1500\n",
            "[INFO|configuration_utils.py:391] 2021-08-27 12:46:34,434 >> Configuration saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-1500/config.json\n",
            "[INFO|modeling_utils.py:1001] 2021-08-27 12:46:44,917 >> Model weights saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-1500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2020] 2021-08-27 12:46:44,925 >> tokenizer config file saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-1500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2026] 2021-08-27 12:46:44,932 >> Special tokens file saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-1500/special_tokens_map.json\n",
            "{'loss': 0.2731, 'learning_rate': 8.592132505175984e-06, 'epoch': 2.48}\n",
            " 83% 2000/2415 [46:39<08:39,  1.25s/it][INFO|trainer.py:1921] 2021-08-27 12:58:38,626 >> Saving model checkpoint to /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-2000\n",
            "[INFO|configuration_utils.py:391] 2021-08-27 12:58:38,637 >> Configuration saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-2000/config.json\n",
            "[INFO|modeling_utils.py:1001] 2021-08-27 12:58:49,427 >> Model weights saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-2000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2020] 2021-08-27 12:58:49,437 >> tokenizer config file saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-2000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2026] 2021-08-27 12:58:49,445 >> Special tokens file saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-2000/special_tokens_map.json\n",
            "100% 2415/2415 [56:59<00:00,  1.25s/it][INFO|trainer.py:1362] 2021-08-27 13:08:57,995 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 3419.2557, 'train_samples_per_second': 0.706, 'train_steps_per_second': 0.706, 'train_loss': 0.4635135089882165, 'epoch': 3.0}\n",
            "100% 2415/2415 [56:59<00:00,  1.42s/it]\n",
            "[INFO|trainer.py:1921] 2021-08-27 13:08:58,055 >> Saving model checkpoint to /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/\n",
            "[INFO|configuration_utils.py:391] 2021-08-27 13:08:58,066 >> Configuration saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/config.json\n",
            "[INFO|modeling_utils.py:1001] 2021-08-27 13:09:11,056 >> Model weights saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2020] 2021-08-27 13:09:11,073 >> tokenizer config file saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2026] 2021-08-27 13:09:11,091 >> Special tokens file saved in /content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  train_loss               =     0.4635\n",
            "  train_runtime            = 0:56:59.25\n",
            "  train_samples            =        805\n",
            "  train_samples_per_second =      0.706\n",
            "  train_steps_per_second   =      0.706\n",
            "08/27/2021 13:09:11 - INFO - __main__ - *** Evaluate ***\n",
            "[INFO|trainer.py:2167] 2021-08-27 13:09:11,448 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2169] 2021-08-27 13:09:11,448 >>   Num examples = 204\n",
            "[INFO|trainer.py:2172] 2021-08-27 13:09:11,448 >>   Batch size = 1\n",
            "100% 204/204 [19:36<00:00,  5.69s/it]08/27/2021 13:28:58 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n",
            "100% 204/204 [19:40<00:00,  5.78s/it]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        3.0\n",
            "  eval_gen_len            =    123.549\n",
            "  eval_loss               =     0.6614\n",
            "  eval_rouge1             =    85.2322\n",
            "  eval_rouge2             =    80.1953\n",
            "  eval_rougeL             =    83.4431\n",
            "  eval_rougeLsum          =    84.7004\n",
            "  eval_runtime            = 0:19:46.66\n",
            "  eval_samples            =        204\n",
            "  eval_samples_per_second =      0.172\n",
            "  eval_steps_per_second   =      0.172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qluwkw0U0AK6"
      },
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
        "\n",
        "PATH = \"/content/drive/MyDrive/Datasests/Scisummnet/Summarization Output/checkpoint-2000\"\n",
        "#model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "model = BartForConditionalGeneration.from_pretrained(PATH, local_files_only=True)\n",
        "#tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "tokenizer = BartTokenizer.from_pretrained(PATH, local_files_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "c402b78302e64d3b890ea26766b748a8",
            "acc1df52ad614a36861e37c8e56a3ba5",
            "1fce8d38a8bb4eaa9e56fb1dd10f6416",
            "3d8c6d784f5f42bfa056a5f7cf193a43",
            "2714ef02e0254d3ab9c90c7bb4408c8a",
            "4a911129ca39438cbf3fbffa8123cf80",
            "bd4e67b9087c45cd94e13cf1846c9157",
            "57a674f194da42d28ada5d133792a981",
            "078e84617e604fe0926fe5b52e590d41",
            "ec205eba934c47a696cc9062158d6784",
            "c9067b241fb146269d82c0b1ce8a8a33"
          ]
        },
        "id": "-5cyMm7xP7O3",
        "outputId": "ef42ab5e-ee58-4cb1-8c6b-8b35f89f47c9"
      },
      "source": [
        "test_df = pd.read_csv('/content/drive/MyDrive/Datasests/Scisummnet/scisumm_test.csv')\n",
        "gen_summs = []\n",
        "for paper in tqdm(test_df.text.values[:203]):\n",
        "#for paper in tqdm(scis_df.text.values[:5]):\n",
        "\n",
        "  ARTICLE_TO_SUMMARIZE = paper\n",
        "  inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors='pt', truncation=True)\n",
        "\n",
        "  # Generate Summary\n",
        "  summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=500, early_stopping=True)\n",
        "  gen_summs.append([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids])\n",
        "\n",
        "gen_df = pd.DataFrame({'generated_summary':gen_summs})\n",
        "gen_df.head()\n",
        "\n",
        "gen_df.generated_summary = gen_df.generated_summary.apply(lambda x: x[0])\n",
        "gen_df.head()\n",
        "\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge2', 'rouge3'])\n",
        "scores = []\n",
        "#mod: sharmaa4 for i in range(500):\n",
        "for i in range(203):\n",
        "  \n",
        "  scores.append(scorer.score(test_df.iloc[i].summary, gen_df.iloc[i].generated_summary))\n",
        "\n",
        "\n",
        "r2r = []\n",
        "r2f = []\n",
        "r3f = []\n",
        "#for i in range(250):\n",
        "for i in range(203):\n",
        "  r2r.append(scores[i]['rouge2'].recall)\n",
        "  r2f.append(scores[i]['rouge2'].fmeasure)\n",
        "  r3f.append(scores[i]['rouge3'].fmeasure)\n",
        "\n",
        "\n",
        "print('rouge2 - recall: '+ str(np.mean(r2r)))\n",
        "print('rouge2 - fmeasure: '+ str(np.mean(r2f)))\n",
        "print('rouge3 - fmeasure: '+ str(np.mean(r3f)))\n",
        "\n",
        "gen_df.to_csv('./nonpt_first500.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c402b78302e64d3b890ea26766b748a8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/203 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rouge2 - recall: 0.531533252893803\n",
            "rouge2 - fmeasure: 0.6378251993752988\n",
            "rouge3 - fmeasure: 0.6190063056925416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTS5CAPORsOe"
      },
      "source": [
        "pretrained_positional_embedding_sizes = 1024 for every model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMvZUg4CR5GC"
      },
      "source": [
        "def gen_pdf_summary(pdf_file_path):\n",
        "    pdf_obj = PyPDF2.PdfFileReader(pdf_file_path)\n",
        "    page_no = pdf_obj.getNumPages()\n",
        "    text = \"\"\n",
        "    for i in range(1, page_no):\n",
        "        text += pdf_obj.getPage(i).extractText()\n",
        "    \n",
        "    inputs_1 = tokenizer(text[0:1024], max_length=1024, return_tensors='pt', truncation=True)\n",
        "    inputs_2 = tokenizer(text[1025:2048], max_length=1024, return_tensors='pt', truncation=True)\n",
        "    inputs_3 = tokenizer(text[2048:3072], max_length=1024, return_tensors='pt', truncation=True)\n",
        "    inputs_4 = tokenizer(text[3072:], max_length=1024, return_tensors='pt', truncation=True)\n",
        "\n",
        "    # Generate Summary\n",
        "    summary_ids_1 = model.generate(inputs_1['input_ids'], num_beams=4, max_length=100, early_stopping=True)\n",
        "    summary_1 = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids_1]\n",
        "\n",
        "    summary_ids_2 = model.generate(inputs_2['input_ids'], num_beams=4, max_length=100, early_stopping=True)\n",
        "    summary_2 = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids_2]\n",
        "\n",
        "    summary_ids_3 = model.generate(inputs_3['input_ids'], num_beams=4, max_length=100, early_stopping=True)\n",
        "    summary_3 = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids_3]\n",
        "\n",
        "    summary_ids_4 = model.generate(inputs_4['input_ids'], num_beams=4, max_length=100, early_stopping=True)\n",
        "    summary_4 = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids_4]\n",
        "  \n",
        "    summary = summary_1[0]+summary_2[0]+summary_3[0]+summary_4[0]\n",
        "    return summary\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "6lEGDOULisZo",
        "outputId": "f7c715c7-b94c-4977-afba-52e1e231a6cb"
      },
      "source": [
        "gen_pdf_summary(\"/content/1909.01716.pdf\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.) [_tensor.py:575]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Asolidsummaryofthe\\ncontent\\nFrom theauthors\\' point of\\nview, it may fail to understand the actual\\nimpact\\nofthe paper on\\ntheresearch community.\\nAdditionally, the authors of a\\npaper may have difficulty understanding the actual pragmatic impact\\nof the paper on the literature community, and may not be able to tackle the various problems in\\npapers summarization.\\nOurcorpus, which contain the information network of ACLAnthIn this paper we present two approaches for estimating the impact of unsupervised paper summarization.\\nThe first approach, based on the authors\\' insight, is to use abstract knowledge, and the second approach, which is based on a knowledge-free approach.\\nIn both models, given the same amount of knowledge, both approaches are able to integrate both approaches.\\nFurther, we propose a method for estimating a paper\\'s impact on a paper based on its authors\\' knowledgeIntroductionWe describe our experience in introducing the concept of \"glossy summarization\" to the literature.\\nWe propose a method for summarization based on the use of network-based summarization models, which are provided by the Architecture of Yasunagaetal (2017)\\'sneural\\nmulti-documents-ummarizer.\\nOur method is based on a highly scalable, highly scalable approach to summarization.\\nIn our experience, this approachIntroduction&Motivation\\nMany existing system-semployed, highly-extractive\\nParameter-based approaches to highly-dimensional, content-based research have been studied in recent years.\\nThis paper presents an account of this research and discusses its results.\\nWe present a general overview of the systems that have taken part in the research and discuss their performance.\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJELAWFlkpIi"
      },
      "source": [
        "took 1m 36s when ran with cpu provided colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOARAOz3thK6"
      },
      "source": [
        "##Trying with gpu\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mSYRvW0tXY9"
      },
      "source": [
        "def gen_pdf_summary(pdf_file_path):\n",
        "    pdf_obj = PyPDF2.PdfFileReader(pdf_file_path)\n",
        "    page_no = pdf_obj.getNumPages()\n",
        "    text = \"\"\n",
        "    for i in range(1, page_no):\n",
        "        text += pdf_obj.getPage(i).extractText()\n",
        "    \n",
        "    inputs_1 = tokenizer(text[0:1024], max_length=1024, return_tensors='pt', truncation=True)\n",
        "    inputs_2 = tokenizer(text[1025:2048], max_length=1024, return_tensors='pt', truncation=True)\n",
        "    inputs_3 = tokenizer(text[2048:3072], max_length=1024, return_tensors='pt', truncation=True)\n",
        "    inputs_4 = tokenizer(text[3072:], max_length=1024, return_tensors='pt', truncation=True)\n",
        "\n",
        "    # Generate Summary\n",
        "    summary_ids_1 = model.generate(inputs_1['input_ids'], num_beams=4, max_length=100, early_stopping=True)\n",
        "    summary_1 = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids_1]\n",
        "\n",
        "    summary_ids_2 = model.generate(inputs_2['input_ids'], num_beams=4, max_length=100, early_stopping=True)\n",
        "    summary_2 = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids_2]\n",
        "\n",
        "    summary_ids_3 = model.generate(inputs_3['input_ids'], num_beams=4, max_length=100, early_stopping=True)\n",
        "    summary_3 = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids_3]\n",
        "\n",
        "    summary_ids_4 = model.generate(inputs_4['input_ids'], num_beams=4, max_length=100, early_stopping=True)\n",
        "    summary_4 = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids_4]\n",
        "  \n",
        "    summary = summary_1[0]+summary_2[0]+summary_3[0]+summary_4[0]\n",
        "    return summary.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5H-WjFptZ7d"
      },
      "source": [
        "summary = gen_pdf_summary(\"/content/1909.01716.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1bFHbHUuAxg"
      },
      "source": [
        "took 1m 29s when ran with GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUWA_YiHuHc9",
        "outputId": "4efea137-7abb-4c78-f794-4744e2ef1c6d"
      },
      "source": [
        "print(summary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Asolidsummaryofthe\n",
            "content\n",
            "From theauthors' point of\n",
            "view, it may fail to understand the actual\n",
            "impact\n",
            "ofthe paper on\n",
            "theresearch community.\n",
            "Additionally, the authors of a\n",
            "paper may have difficulty understanding the actual pragmatic impact\n",
            "of the paper on the literature community, and may not be able to tackle the various problems in\n",
            "papers summarization.\n",
            "Ourcorpus, which contain the information network of ACLAnthIn this paper we present two approaches for estimating the impact of unsupervised paper summarization.\n",
            "The first approach, based on the authors' insight, is to use abstract knowledge, and the second approach, which is based on a knowledge-free approach.\n",
            "In both models, given the same amount of knowledge, both approaches are able to integrate both approaches.\n",
            "Further, we propose a method for estimating a paper's impact on a paper based on its authors' knowledgeIntroductionWe describe our experience in introducing the concept of \"glossy summarization\" to the literature.\n",
            "We propose a method for summarization based on the use of network-based summarization models, which are provided by the Architecture of Yasunagaetal (2017)'sneural\n",
            "multi-documents-ummarizer.\n",
            "Our method is based on a highly scalable, highly scalable approach to summarization.\n",
            "In our experience, this approachIntroduction&Motivation\n",
            "Many existing system-semployed, highly-extractive\n",
            "Parameter-based approaches to highly-dimensional, content-based research have been studied in recent years.\n",
            "This paper presents an account of this research and discusses its results.\n",
            "We present a general overview of the systems that have taken part in the research and discuss their performance.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ko3S09_uwkj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}